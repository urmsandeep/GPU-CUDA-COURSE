{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Lab-1: count_theads.cu and hello.cu**\n",
        "\n",
        "03-11-25, v1.0, (c) Incubera AI Labs\n",
        "\n",
        "**This an introduction to GPU parallelism. ***\n",
        "\n",
        "Here's what your learn:\n",
        "\n",
        "*   Count number of threads\n",
        "*   We write **once** run many copies\n",
        "*   Code Runs in Multiple Places at Once\n",
        "*   We can concurrenlty launch multiple (\"n\") copies of a function (e.g. n=1000)\n",
        "*   GPU executes all copies in **parallel**\n",
        "*   Each thread gets a **unique ID** (0-(n-1)) automatically\n",
        "*   Functions **at the same time**, not one after another"
      ],
      "metadata": {
        "id": "UlaNX0bpKW5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "QxuFYjNLe9u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "id": "j_-Xn8dfgcpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile count_threads.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "//  Cardinality (Number of Threads)\n",
        "__global__ void countThreads() {\n",
        "    // Thread's position within its block\n",
        "    int thread_in_block = threadIdx.x;\n",
        "\n",
        "    // Which block am I in?\n",
        "    int my_block = blockIdx.x;\n",
        "\n",
        "    // My unique global thread ID\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Total threads in the grid\n",
        "    int total_threads = gridDim.x * blockDim.x;\n",
        "\n",
        "    printf(\"Block %d, Thread %d â†’ Global ID: %d (Total: %d threads)\\n\",\n",
        "           my_block, thread_in_block, global_id, total_threads);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Launching with <<<2, 5>>> (2 blocks, 5 threads each)\\n\\n\");\n",
        "    countThreads<<<2, 5>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "_VieuCRTPUV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 count_threads.cu -o count_threads\n"
      ],
      "metadata": {
        "id": "f9iK_UlIPnaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./count_threads"
      ],
      "metadata": {
        "id": "8-QGrq_OPtio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHbG8eMsb4gd"
      },
      "outputs": [],
      "source": [
        "%%writefile hello.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "//\n",
        "__global__ void helloKernel() {\n",
        "    printf(\"Hello from thread %d!\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Check if CUDA device is available\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    printf(\"Found %d CUDA devices\\n\", deviceCount);\n",
        "\n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"No CUDA devices found!\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Set larger printf buffer BEFORE launching kernel\n",
        "    cudaDeviceSetLimit(cudaLimitPrintfFifoSize, 1024*1024*10);\n",
        "\n",
        "    printf(\"Launching kernel from CPU...\\n\");\n",
        "\n",
        "    // 1 block, 100 threads\n",
        "    helloKernel<<<1, 1000>>>();\n",
        "\n",
        "    // Check for launch errors\n",
        "    cudaError_t launchErr = cudaGetLastError();\n",
        "    if (launchErr != cudaSuccess) {\n",
        "        printf(\"Kernel launch error: %s\\n\", cudaGetErrorString(launchErr));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Wait and check for execution errors\n",
        "    cudaError_t syncErr = cudaDeviceSynchronize();\n",
        "    if (syncErr != cudaSuccess) {\n",
        "        printf(\"Kernel execution error: %s\\n\", cudaGetErrorString(syncErr));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Force flush - this is key!\n",
        "    cudaDeviceReset();\n",
        "\n",
        "    printf(\"GPU finished!\\n\");\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 hello.cu -o hello\n"
      ],
      "metadata": {
        "id": "mwhJPoWncK4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "id": "Zx6zsTzUcSVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}