{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**(3a) Simplified Vector Addition with debugs**\n",
        "\n",
        "*   Only 10 elements (easy to print all elements)\n",
        "*   Prints from both CPU and GPU\n",
        "*   Shows each step clearly"
      ],
      "metadata": {
        "id": "e0FdaKLm5Rkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v5s5R2ZMUQY"
      },
      "outputs": [],
      "source": [
        "%%writefile vector_add_debug.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// GPU KERNEL - Runs on Device\n",
        "__global__ void vectorAdd(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "        // Debug: print from first few threads\n",
        "        if (i < 5) {\n",
        "            printf(\"GPU Thread %d: %f + %f = %f\\n\", i, a[i], b[i], c[i]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 10;  // Start with just 10 elements for easy debugging\n",
        "    size_t bytes = n * sizeof(float);\n",
        "\n",
        "    // 1. Allocate and initialize on CPU\n",
        "    //    The CPU creates two arrays in its own memory (RAM)\n",
        "    float *h_a = (float*)malloc(bytes);\n",
        "    float *h_b = (float*)malloc(bytes);\n",
        "    float *h_c = (float*)malloc(bytes);\n",
        "\n",
        "    printf(\"=== CPU Initialization ===\\n\");\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = (float)i;\n",
        "        h_b[i] = (float)(i * 2);\n",
        "        printf(\"CPU: h_a[%d] = %f, h_b[%d] = %f\\n\", i, h_a[i], i, h_b[i]);\n",
        "    }\n",
        "\n",
        "    // 2. Allocate GPU memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    // 3. Copy to GPU\n",
        "    // Data is transferred from CPU RAM â†’ GPU VRAM\n",
        "    // This happens over the PCI-Express bus\n",
        "    // (the connection between CPU and GPU)\n",
        "    // Now the GPU has copies of arrays `a` and `b` in its own memory\n",
        "    printf(\"\\n=== Copying to GPU ===\\n\");\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // 4. Launch kernel\n",
        "    printf(\"\\n=== GPU Computation ===\\n\");\n",
        "    vectorAdd<<<1, n>>>(d_a, d_b, d_c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "    // Check for errors\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"ERROR: %s\\n\", cudaGetErrorString(error));\n",
        "    }\n",
        "\n",
        "    // 5. Copy back\n",
        "    printf(\"\\n=== Copying from GPU ===\\n\");\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // 6. Verify results\n",
        "    printf(\"\\n=== CPU Verification ===\\n\");\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        float expected = h_a[i] + h_b[i];\n",
        "        printf(\"c[%d] = %f (expected %f) %s\\n\",\n",
        "               i, h_c[i], expected,\n",
        "               (h_c[i] == expected) ? \"âœ“\" : \"âœ—\");\n",
        "    }\n",
        "\n",
        "    // 7. Cleanup\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o vector_debug vector_add_debug.cu\n"
      ],
      "metadata": {
        "id": "1qTtRRkHemuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_debug"
      ],
      "metadata": {
        "id": "F9xd9EHDesLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***(3b) Large date set (Million elements) Vector Addition***\n",
        "\n",
        "*   We will now try with **1 Million elements** (10 Lakhs)\n",
        "*   Data set is initialized in CPU and transferred to GPU for addition\n",
        "*   Results copied back to CPU\n"
      ],
      "metadata": {
        "id": "_kIASFfI4R4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-_UGpWbe5QCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add_million.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <time.h>\n",
        "\n",
        "// GPU KERNEL - Runs on Device\n",
        "__global__ void vectorAdd(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU version for comparison\n",
        "void vectorAddCPU(float *a, float *b, float *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000000;  // 1 million elements\n",
        "    size_t bytes = n * sizeof(float);\n",
        "\n",
        "    printf(\"=== Vector Addition: %d elements ===\\n\\n\", n);\n",
        "\n",
        "    // 1. Allocate and initialize on CPU\n",
        "    printf(\"1. Allocating CPU memory...\\n\");\n",
        "    float *h_a = (float*)malloc(bytes);\n",
        "    float *h_b = (float*)malloc(bytes);\n",
        "    float *h_c = (float*)malloc(bytes);\n",
        "    float *h_c_cpu = (float*)malloc(bytes);  // For CPU comparison\n",
        "\n",
        "    printf(\"2. Initializing arrays...\\n\");\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = (float)i;\n",
        "        h_b[i] = (float)(i * 2);\n",
        "    }\n",
        "\n",
        "    // Show a few sample values\n",
        "    printf(\"   Sample: a[0]=%0.f, b[0]=%0.f\\n\", h_a[0], h_b[0]);\n",
        "    printf(\"   Sample: a[999999]=%0.f, b[999999]=%0.f\\n\\n\", h_a[999999], h_b[999999]);\n",
        "\n",
        "    // === CPU TIMING ===\n",
        "    printf(\"3. Running CPU version...\\n\");\n",
        "    clock_t cpu_start = clock();\n",
        "    vectorAddCPU(h_a, h_b, h_c_cpu, n);\n",
        "    clock_t cpu_end = clock();\n",
        "    double cpu_time = ((double)(cpu_end - cpu_start)) / CLOCKS_PER_SEC * 1000.0;\n",
        "    printf(\"   CPU Time: %.2f ms\\n\\n\", cpu_time);\n",
        "\n",
        "    // === GPU SETUP ===\n",
        "    printf(\"4. Allocating GPU memory...\\n\");\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    printf(\"5. Copying data to GPU...\\n\");\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // === GPU TIMING ===\n",
        "    printf(\"6. Running GPU version...\\n\");\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"   Grid: %d blocks x %d threads = %d total threads\\n\",\n",
        "           blocksPerGrid, threadsPerBlock, blocksPerGrid * threadsPerBlock);\n",
        "\n",
        "    // Warm-up run\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Timed run\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "    printf(\"   GPU Time: %.2f ms\\n\\n\", gpu_time);\n",
        "\n",
        "    // Check for errors\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"   ERROR: %s\\n\", cudaGetErrorString(error));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    printf(\"7. Copying results back to CPU...\\n\");\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // === VERIFICATION ===\n",
        "    printf(\"8. Verifying results...\\n\");\n",
        "    int errors = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        float expected = h_a[i] + h_b[i];\n",
        "        if (h_c[i] != expected) {\n",
        "            errors++;\n",
        "            if (errors <= 5) {  // Show only first 5 errors\n",
        "                printf(\"   Error at index %d: got %f, expected %f\\n\",\n",
        "                       i, h_c[i], expected);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (errors == 0) {\n",
        "        printf(\"   âœ“ All %d values correct!\\n\\n\", n);\n",
        "    } else {\n",
        "        printf(\"   âœ— Found %d errors out of %d values\\n\\n\", errors, n);\n",
        "    }\n",
        "\n",
        "    // Show sample results\n",
        "    printf(\"Sample Results:\\n\");\n",
        "    printf(\"   c[0] = %0.f (expected %0.f)\\n\", h_c[0], h_a[0] + h_b[0]);\n",
        "    printf(\"   c[1] = %0.f (expected %0.f)\\n\", h_c[1], h_a[1] + h_b[1]);\n",
        "    printf(\"   c[999999] = %0.f (expected %0.f)\\n\\n\", h_c[999999], h_a[999999] + h_b[999999]);\n",
        "\n",
        "    // === PERFORMANCE COMPARISON ===\n",
        "    printf(\"=== Performance Summary ===\\n\");\n",
        "    printf(\"CPU Time: %.2f ms\\n\", cpu_time);\n",
        "    printf(\"GPU Time: %.2f ms\\n\", gpu_time);\n",
        "    printf(\"Speedup: %.1fx faster on GPU! ðŸš€\\n\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    // Cleanup\n",
        "    printf(\"9. Cleaning up...\\n\");\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    free(h_c_cpu);\n",
        "\n",
        "    printf(\"Done! âœ“\\n\");\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "lR6spIB8MZJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add_million.cu -o vector_add_million\n"
      ],
      "metadata": {
        "id": "3iKz1gTOMvX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add_million"
      ],
      "metadata": {
        "id": "RgWDrhXVM6aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***(3c) Large date set (Million elements) Vector Addition (Data directly in GPU***\n",
        "\n",
        "*   We will now try with **1 Million elements** (10 Lakhs)\n",
        "*   Data set is initialized directly in GPU\n",
        "*   Results copied back to CPU\n"
      ],
      "metadata": {
        "id": "bWTph2ST5MCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add_million_gpu_init.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <time.h>\n",
        "\n",
        "// GPU KERNEL - Initialize arrays on GPU\n",
        "__global__ void initArrays(float *a, float *b, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        a[i] = (float)i;\n",
        "        b[i] = (float)(i * 2);\n",
        "    }\n",
        "}\n",
        "\n",
        "// GPU KERNEL - Add vectors\n",
        "__global__ void vectorAdd(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU version for comparison\n",
        "void vectorAddCPU(float *a, float *b, float *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000000;  // 1 million elements\n",
        "    size_t bytes = n * sizeof(float);\n",
        "\n",
        "    printf(\"=== Vector Addition: %d elements ===\\n\", n);\n",
        "    printf(\"*** Initializing arrays ON GPU ***\\n\\n\");\n",
        "\n",
        "    // Allocate CPU memory (only for results and verification)\n",
        "    float *h_c = (float*)malloc(bytes);\n",
        "\n",
        "    // === GPU MEMORY ALLOCATION ===\n",
        "    printf(\"1. Allocating GPU memory...\\n\");\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    // === GPU INITIALIZATION ===\n",
        "    printf(\"2. Initializing arrays ON GPU (not on CPU!)...\\n\");\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    cudaEvent_t init_start, init_stop;\n",
        "    cudaEventCreate(&init_start);\n",
        "    cudaEventCreate(&init_stop);\n",
        "\n",
        "    cudaEventRecord(init_start);\n",
        "    initArrays<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, n);\n",
        "    cudaEventRecord(init_stop);\n",
        "    cudaEventSynchronize(init_stop);\n",
        "\n",
        "    float init_time = 0;\n",
        "    cudaEventElapsedTime(&init_time, init_start, init_stop);\n",
        "    printf(\"   GPU Initialization Time: %.2f ms\\n\", init_time);\n",
        "    printf(\"   Grid: %d blocks x %d threads\\n\\n\", blocksPerGrid, threadsPerBlock);\n",
        "\n",
        "    // Verify initialization (copy a few values back to check)\n",
        "    float test_a[3], test_b[3];\n",
        "    cudaMemcpy(test_a, d_a, 3 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(test_b, d_b, 3 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    printf(\"   Verification: a[0]=%0.f, a[1]=%0.f, a[2]=%0.f\\n\", test_a[0], test_a[1], test_a[2]);\n",
        "    printf(\"   Verification: b[0]=%0.f, b[1]=%0.f, b[2]=%0.f\\n\\n\", test_b[0], test_b[1], test_b[2]);\n",
        "\n",
        "    // === GPU COMPUTATION ===\n",
        "    printf(\"3. Running GPU vector addition...\\n\");\n",
        "\n",
        "    // Warm-up run\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Timed run\n",
        "    cudaEvent_t compute_start, compute_stop;\n",
        "    cudaEventCreate(&compute_start);\n",
        "    cudaEventCreate(&compute_stop);\n",
        "\n",
        "    cudaEventRecord(compute_start);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
        "    cudaEventRecord(compute_stop);\n",
        "    cudaEventSynchronize(compute_stop);\n",
        "\n",
        "    float compute_time = 0;\n",
        "    cudaEventElapsedTime(&compute_time, compute_start, compute_stop);\n",
        "    printf(\"   GPU Computation Time: %.2f ms\\n\\n\", compute_time);\n",
        "\n",
        "    // Check for errors\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"   ERROR: %s\\n\", cudaGetErrorString(error));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // === COPY RESULTS ===\n",
        "    printf(\"4. Copying results back to CPU...\\n\");\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // === VERIFICATION ===\n",
        "    printf(\"5. Verifying results...\\n\");\n",
        "    int errors = 0;\n",
        "    int samples_to_check = 1000;  // Check first and last 1000\n",
        "\n",
        "    // Check first 1000\n",
        "    for (int i = 0; i < samples_to_check && i < n; i++) {\n",
        "        float expected = (float)i + (float)(i * 2);  // a[i] + b[i]\n",
        "        if (h_c[i] != expected) {\n",
        "            errors++;\n",
        "            if (errors <= 3) {\n",
        "                printf(\"   Error at index %d: got %f, expected %f\\n\",\n",
        "                       i, h_c[i], expected);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Check last 1000\n",
        "    for (int i = n - samples_to_check; i < n; i++) {\n",
        "        float expected = (float)i + (float)(i * 2);\n",
        "        if (h_c[i] != expected) {\n",
        "            errors++;\n",
        "            if (errors <= 3) {\n",
        "                printf(\"   Error at index %d: got %f, expected %f\\n\",\n",
        "                       i, h_c[i], expected);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (errors == 0) {\n",
        "        printf(\"   âœ“ All checked values correct!\\n\\n\");\n",
        "    } else {\n",
        "        printf(\"   âœ— Found %d errors\\n\\n\", errors);\n",
        "    }\n",
        "\n",
        "    // Show sample results\n",
        "    printf(\"Sample Results:\\n\");\n",
        "    printf(\"   c[0] = %0.f (expected 0)\\n\", h_c[0]);\n",
        "    printf(\"   c[1] = %0.f (expected 3)\\n\", h_c[1]);\n",
        "    printf(\"   c[2] = %0.f (expected 6)\\n\", h_c[2]);\n",
        "    printf(\"   c[999999] = %0.f (expected 2999997)\\n\\n\", h_c[999999]);\n",
        "\n",
        "    // === PERFORMANCE SUMMARY ===\n",
        "    printf(\"=== Performance Summary ===\\n\");\n",
        "    printf(\"GPU Initialization: %.2f ms\\n\", init_time);\n",
        "    printf(\"GPU Computation:    %.2f ms\\n\", compute_time);\n",
        "    printf(\"Total GPU Time:     %.2f ms\\n\\n\", init_time + compute_time);\n",
        "\n",
        "    printf(\"ðŸ’¡ Benefits of GPU initialization:\\n\");\n",
        "    printf(\"   âœ“ No CPU initialization needed\\n\");\n",
        "    printf(\"   âœ“ No CPUâ†’GPU transfer of input data\\n\");\n",
        "    printf(\"   âœ“ Data lives entirely on GPU\\n\");\n",
        "    printf(\"   âœ“ Only transfer results back\\n\\n\");\n",
        "\n",
        "    // Cleanup\n",
        "    printf(\"6. Cleaning up...\\n\");\n",
        "    cudaEventDestroy(init_start);\n",
        "    cudaEventDestroy(init_stop);\n",
        "    cudaEventDestroy(compute_start);\n",
        "    cudaEventDestroy(compute_stop);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Done! âœ“\\n\");\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "pMyJww2y5Ldu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add_million_gpu_init.cu -o vector_add_million_gpu_init\n"
      ],
      "metadata": {
        "id": "97IC77gbACtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add_million_gpu_init"
      ],
      "metadata": {
        "id": "vkwFL2isAPlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Benefits of GPU Initialization\n",
        "\n",
        "\n",
        "*   No CPU initialization loop - saves CPU time\n",
        "*   No CPUâ†’GPU transfer - saves PCIe bandwidth\n",
        "*   Data lives entirely on GPU - more efficient\n",
        "*   Only transfer results back - minimal data movement\n"
      ],
      "metadata": {
        "id": "ZPauFQ6oAY0Y"
      }
    }
  ]
}